{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "----\n",
    "# Functions and Settings for HOMM webscrapper\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Install a pip package in the current Jupyter kernel\\nimport sys\\nprint(\"-------------------------------------\\nInstalling - All requirements\")\\n# pip\\n\\n!python -m pip install numpy\\n!python -m pip install pandas\\n!python -m pip install matplotlib\\n\\n!python -m pip install requests>=2.23.0\\n!python -m pip install beautifulsoup4==4.7.1\\n!python -m pip install fake-useragent==0.1.11\\n!python -m pip install google==3.0.0\\n!python -m pip install openpyxl\\n!python -m pip install xlrd\\n# conda\\n#!conda install --yes --prefix {sys.prefix} numpy\\n\\nprint(\"==> DONE - installing.\")\\nprint(\"-------------------------------------\\nImporting - All requirements\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on article\n",
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "\"\"\"\n",
    "!pip install requests>=2.23.0 --quiet --yes --user\n",
    "!pip install beautifulsoup4==4.7.1 --quiet --yes --user\n",
    "#!pip install pandas --quiet --yes --user \n",
    "#!pip install numpy --quiet --yes --user\n",
    "#!pip install matplotlib --quiet --yes --user\n",
    "#!pip install requests==2.21.0 --quiet --user \n",
    "!pip install fake-useragent==0.1.11 --quiet --yes  --user \n",
    "!pip install google==3.0.0 --quiet --yes --user\n",
    "!pip install openpyxl --quiet --yes --user\n",
    "!pip install xlrd --quiet --yes --user\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "print(\"-------------------------------------\\nInstalling - All requirements\")\n",
    "# pip\n",
    "!{sys.executable} -m pip install requests>=2.23.0\n",
    "!{sys.executable} -m pip install beautifulsoup4==4.7.1\n",
    "!{sys.executable} -m pip install fake-useragent==0.1.11\n",
    "!{sys.executable} -m pip install google==3.0.0\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install xlrd\n",
    "# conda\n",
    "#!conda install --yes --prefix {sys.prefix} numpy\n",
    "#print(\"==> DONE - installing.\")\n",
    "#print(\"-------------------------------------\\nImporting - All requirements\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "print(\"-------------------------------------\\nInstalling - All requirements\")\n",
    "# pip\n",
    "\n",
    "!python -m pip install numpy\n",
    "!python -m pip install pandas\n",
    "!python -m pip install matplotlib\n",
    "\n",
    "!python -m pip install requests>=2.23.0\n",
    "!python -m pip install beautifulsoup4==4.7.1\n",
    "!python -m pip install fake-useragent==0.1.11\n",
    "!python -m pip install google==3.0.0\n",
    "!python -m pip install openpyxl\n",
    "!python -m pip install xlrd\n",
    "# conda\n",
    "#!conda install --yes --prefix {sys.prefix} numpy\n",
    "\n",
    "print(\"==> DONE - installing.\")\n",
    "print(\"-------------------------------------\\nImporting - All requirements\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> DONE - importing.\n",
      "----------------------------------------\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import traceback\n",
    "\n",
    "from random import randint\n",
    "import time\n",
    "import datetime as dt\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from itertools import cycle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "print(\"==> DONE - importing.\\n----------------------------------------\")\n",
    "\n",
    "try: \n",
    "    from googlesearch import search \n",
    "except ImportError:  \n",
    "    print(\"No module named 'google' found\") \n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2. Set Globals - Folders and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "..\\results\\archive\n",
      "..\\results\\latest\n",
      "..\\sources\n",
      "Folder already exists:  .\n",
      "Folder already exists:  ..\\results\\archive\n",
      "Folder already exists:  ..\\results\\latest\n",
      "Folder already exists:  ..\\sources\n",
      "Search terms df shape:  (13, 3)\n"
     ]
    }
   ],
   "source": [
    "# folders\n",
    "CURRENT_DIR = os.curdir; print(CURRENT_DIR)\n",
    "RESULTS_ARCHIVE = os.path.join(\"..\", \"results\", \"archive\"); print(RESULTS_ARCHIVE)\n",
    "RESULTS_LATEST = os.path.join(\"..\", \"results\", \"latest\"); print(RESULTS_LATEST)\n",
    "SOURCES = os.path.join(\"..\", \"sources\"); print(SOURCES)\n",
    "dirs = [CURRENT_DIR, RESULTS_ARCHIVE, RESULTS_LATEST, SOURCES]\n",
    "\n",
    "for fn in dirs:\n",
    "    if not os.path.exists(fn): \n",
    "        print(\"Making folder: \", fn)\n",
    "        os.mkdir(fn)\n",
    "    else:\n",
    "        print(\"Folder already exists: \", fn)\n",
    "\n",
    "# search terms\n",
    "search_terms = \"SearchTerms_MasterList.csv\"\n",
    "df_searchterms = pd.read_csv(os.path.join(SOURCES, search_terms))\n",
    "print(\"Search terms df shape: \", df_searchterms.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 3. Set Globals - Config and Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Set globals for Google Search\n",
    "global dict_googledfs_lastmonth, dict_googledfs_alltime\n",
    "dict_googledfs_lastmonth = {}\n",
    "dict_googledfs_alltime = {}\n",
    "\n",
    "# Programmables Search Engine settings/config\n",
    "global dict_hvddfs_alltime, dict_ngodfs_alltime, dict_igodfs_alltime, dict_psedfs_alltime\n",
    "dict_hvddfs_alltime = {}\n",
    "dict_ngodfs_alltime = {}\n",
    "dict_igodfs_alltime = {}\n",
    "dict_psedfs_alltime = {} # This is for the custom search engine, may not be used going forward\n",
    "\n",
    "# ReliefWeb and United Nations settings/config\n",
    "global dict_rwdfs_alltime, dict_undfs_alltime\n",
    "dict_rwdfs_alltime = {}\n",
    "dict_undfs_alltime = {}\n",
    "\n",
    "all_searchterms = ['\"'+q+'\"' + ' ' +'\"'+appendix+'\"' for q, appendix \n",
    "                   in zip(df_searchterms.product_title, df_searchterms.append_to_term)]\n",
    "print(all_searchterms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4. Utility Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### *Proxies and Requests*\n",
    "- https://httpbin.org/ip  : gives you back your ip addres\n",
    "- 'https://www.sslproxies.org/': gives you proxies\n",
    "- library `fake_user_agent` gives you headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def get_IPaddress(proxies = None): \n",
    "    url = \"https://httpbin.org/ip\"\n",
    "    \n",
    "    if proxies == None:\n",
    "        print(proxies)\n",
    "        res = requests.get(url)\n",
    "        print(res.text)\n",
    "    else:\n",
    "        print(proxies)\n",
    "        res = requests.get(url, proxies)\n",
    "        print(res.text)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(); ua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### *Task complete - signal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def complete_signal(task):\n",
    "    t = dt.datetime.now()\n",
    "    dd = str(t.year).zfill(2)+\"/\"+str(t.month).zfill(2)+\"/\"+str(t.day).zfill(2)\n",
    "    tt= str(t.hour).zfill(2)+\":\"+str(t.minute).zfill(2)+\":\"+str(t.second).zfill(2)\n",
    "    tstamp = dd+\"   \"+tt\n",
    "    # build a rectangle in axes coords\n",
    "    left, width = .25, .5\n",
    "    bottom, height = .25, .5\n",
    "    right = left + width\n",
    "    top = bottom + height\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    \n",
    "    ax.text(0.8*(left+right), 0.8*(bottom+top), \"\\n\"+task+\" - COMPLETE!\\n\\n---------\\n Time: \"+tstamp,\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center',\n",
    "            fontsize=40, color='black',\n",
    "            backgroundcolor=\"lightgreen\",\n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "complete_signal(task = \"Running on Binder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### *Combine and Save Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def singleitem_and_save(df, source, title, time_window):\n",
    "    today = dt.date.today(); datename = str(today.year)+str(today.month).zfill(2)+str(today.day).zfill(2)\n",
    "    df.to_excel(os.path.join(RESULTS_ARCHIVE,source+\"_\"+title+\"_\"+time_window+\"_\"+datename+\".xlsx\"),\n",
    "                index=False)\n",
    "    df.to_excel(os.path.join(RESULTS_LATEST, source+\"_\"+title+\"_\"+time_window+\"_Latest.xlsx\"),\n",
    "                index=False)\n",
    "    print(\"Completed scraping and file saved for: \", source, \" --> \", title)\n",
    "    return \n",
    "\n",
    "def singleitem_and_save_v2(df, source, title, time_window):\n",
    "    today = dt.date.today(); datename = str(today.year)+str(today.month).zfill(2)+str(today.day).zfill(2)\n",
    "    df.to_excel(os.path.join(RESULTS_ARCHIVE,source+\"_\"+title+\"_\"+time_window+\"_\"+datename+\".xlsx\"),\n",
    "                index=False)\n",
    "    df.to_excel(os.path.join(RESULTS_LATEST, source+\"_\"+title+\"_\"+time_window+\"_Latest.xlsx\"),\n",
    "                index=False)\n",
    "    print(\"Completed scraping and file saved for: \", source, \" --> \", title)\n",
    "    return \n",
    "\n",
    "def combine_and_save(df_list, source, time_window):\n",
    "    combined = pd.concat(df_list);\n",
    "    today = dt.date.today(); datename = str(today.year)+str(today.month).zfill(2)+str(today.day).zfill(2)\n",
    "    combined.to_excel(os.path.join(RESULTS_ARCHIVE,source+\"_\"+time_window+\"_\"+datename+\".xlsx\"), index=False)\n",
    "    combined.to_excel(os.path.join(RESULTS_LATEST,source+\"_\"+time_window+\"_Latest.xlsx\"), index=False)\n",
    "    return complete_signal(\"Scraping \"+ source +\" \"+time_window)\n",
    "\n",
    "singleitem_and_save_v2(pd.DataFrame(all_searchterms), \"Here\", \"Binded\", \"Now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### *Get Reference info from Humanitarian Outcomes* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# get publication titles for HO website\n",
    "def get_publication_titles(url_src):\n",
    "    #url_src = \"https://www.humanitarianoutcomes.org/publications\"\n",
    "    # go to HO website url\n",
    "    #r = requests.get(url_src)\n",
    "    #soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # scrap for titles\n",
    "    with open(os.path.join(SOURCES, \"20200825_publications.txt\"), \"r\") as f:    \n",
    "        txt = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(txt, \"html.parser\")\n",
    "    \n",
    "    # return as list\n",
    "    titles = [h.text for h in [d.find_all(\"h2\") for d in sp.find_all(\"div\", class_ = \"content\")][0]]\n",
    "    exc = 'Subscribe to our mailing list', 'Filter Publications'\n",
    "    \n",
    "    u_titles = []\n",
    "    for t in titles:\n",
    "        if t not in exc and t not in u_titles:\n",
    "            u_titles.append(t)\n",
    "    print(\"number of pubs: \", len(u_titles))\n",
    "    \n",
    "    return u_titles \n",
    "\n",
    "publications = get_publication_titles()\n",
    "print(publications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "hide_input": false,
  "kernelspec": {
   "display_name": "envcitation",
   "language": "python",
   "name": "envcitation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}